{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>category</th>\n",
       "      <th>score</th>\n",
       "      <th>good</th>\n",
       "      <th>bad</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3I92N6EHQI3IP</td>\n",
       "      <td>B000ERAON2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ultimate portable amazing much prices fallen p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2UQK3DAZ8NO2T</td>\n",
       "      <td>B000N48GEU</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>potential king compacts nikon two newest lcd e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1LKSZ9CYJ6829</td>\n",
       "      <td>300110308</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>crossfire become conversation according author...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2YC63G8RC4ILQ</td>\n",
       "      <td>B002QEBMAK</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>great external drive money elements replaced s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3DRQQ9DIFW5W9</td>\n",
       "      <td>425234339</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>least better last got book library given buyin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reviewer_id        asin  overall  category     score  good  bad  \\\n",
       "0  A3I92N6EHQI3IP  B000ERAON2        5        10  0.850000     1    0   \n",
       "1  A2UQK3DAZ8NO2T  B000N48GEU        5        10  0.960784     1    0   \n",
       "2  A1LKSZ9CYJ6829   300110308        3         5  0.727273     0    0   \n",
       "3  A2YC63G8RC4ILQ  B002QEBMAK        4        10  0.888889     1    0   \n",
       "4  A3DRQQ9DIFW5W9   425234339        3         5  0.100000     0    1   \n",
       "\n",
       "                                         review_text  \n",
       "0  ultimate portable amazing much prices fallen p...  \n",
       "1  potential king compacts nikon two newest lcd e...  \n",
       "2  crossfire become conversation according author...  \n",
       "3  great external drive money elements replaced s...  \n",
       "4  least better last got book library given buyin...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_train_test(df, test_size):\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=random.randint(0, 99))\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "    return train, test\n",
    "\n",
    "dataset_path = 'new_data_william.csv' # Minimized dataset\n",
    "\n",
    "df = pd.read_csv(dataset_path, sep=',', index_col=0)\n",
    "\n",
    "# Training: 60%, Validation: 20%, Testing: 20%\n",
    "df_train, df_test = split_train_test(df, 0.200)\n",
    "df_train, df_val = split_train_test(df_train, 0.250)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting tf-idf featurizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.     ,  0.     ,  0.     , ...,  0.14104,  0.     ,  0.     ],\n",
       "       [ 0.     ,  0.     ,  0.     , ...,  0.     ,  0.     ,  0.     ],\n",
       "       [ 0.     ,  0.     ,  0.     , ...,  0.     ,  0.     ,  0.     ],\n",
       "       ..., \n",
       "       [ 0.     ,  0.     ,  0.     , ...,  0.     ,  0.     ,  0.     ],\n",
       "       [ 0.     ,  0.     ,  0.     , ...,  0.     ,  0.     ,  0.     ],\n",
       "       [ 0.     ,  0.     ,  0.     , ...,  0.     ,  0.     ,  0.     ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TfidfFeaturizer(object):\n",
    "    def __init__(self, col_name='review_text', max_features=1000):\n",
    "        self.col_name = col_name\n",
    "        self.max_features = max_features\n",
    "        self.vectorizer = None\n",
    "        \n",
    "    def fit_transform(self, df):\n",
    "        docs = self.__create_doc_list(df)\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            ngram_range=(1,3),\n",
    "            max_features=self.max_features\n",
    "        )\n",
    "        return (self.vectorizer.fit_transform(docs)).toarray()\n",
    "\n",
    "    def transform(self, df):\n",
    "        if self.vectorizer is not None:\n",
    "            docs = self.__create_doc_list(df)\n",
    "            return (self.vectorizer.transform(docs)).toarray()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __create_doc_list(self, df):\n",
    "        return df[self.col_name].tolist()\n",
    "\n",
    "n_tfidf_features = 500\n",
    "tfidf_featurizer = TfidfFeaturizer(max_features=n_tfidf_features)\n",
    "\n",
    "print('Fitting tf-idf featurizer.')\n",
    "tfidf_featurizer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vectorizer_v2.pk', 'wb') as fin:\n",
    "    pickle.dump(tfidf_featurizer, fin, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bad_review = pd.read_csv('data_wei_kitchen_0.3.csv', sep=',', index_col=0)\n",
    "tfidf_bad_review = tfidf_featurizer.transform(bad_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_review['predict_prob'] = model.predict(tfidf_bad_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 544/1107 [=============>................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "bad_review['predict_classes'] = model.predict_classes(tfidf_bad_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "counter_0 = 0\n",
    "for i in bad_review['predict_classes']:\n",
    "    if i == 0:\n",
    "        counter_0 = counter_0 + 1\n",
    "print(counter_0/len(bad_review))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_review.to_csv('bad_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32672/32920 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "good_review = pd.read_csv('data_wei_kitchen_0.8.csv', sep=',', index_col=0)\n",
    "tfidf_good_review = tfidf_featurizer.transform(good_review)\n",
    "good_review['predict_prob'] = model.predict(tfidf_good_review)\n",
    "good_review['predict_classes'] = model.predict_classes(tfidf_good_review)\n",
    "good_review.to_csv('good_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56455042527339\n"
     ]
    }
   ],
   "source": [
    "counter_1 = 0\n",
    "for i in good_review['predict_classes']:\n",
    "    if i == 0:\n",
    "        counter_1 = counter_1 + 1\n",
    "print(counter_1/len(good_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
